---
title: "BC AF Trade Tool Update"
author: "Leila Bautista"
date: "`r Sys.Date()`"
output:
  html_document: default
  pdf_document: default
---

# BC AF Trade Tool Update

This RMarkdown provides chunks of R code to load, filter and combine data from Open Government [website](https://search.open.canada.ca/opendata/?sort=metadata_modified+desc&search_text=cimt&page=1). The trade data is used by the Ministry of Agriculture and Food's Sector Insights and Corporate Initiatives (SICI) Unit to produce annual Sector Tables, Trade Dashboards and other information products.

Contact [alstats\@gov.bc.ca](mailto:alstats@gov.bc.ca) for any questions.

<<<<<<< Updated upstream
# Set-up & Library
=======
1.  Set-up and load library

2.  Load and read the updated (i.e., latest data) for

    a\. domestic export\*

    b\. import

3.  Calculate trade balance

4.  Append the update to the shared structured and time series data called [**TradeFull.csv**]{.underline}

5.  Overwrite [**TradeFull.csv**]{.underline} with the new year's data

\*A new chunk to load **c. Total export** could be written which would require binding with **a. Domestic export** to pivot wide by export type (i.e., total vs. domestic). Once pivoted wide, re-export is equal to total export less domestic export and can be calculated. After calculating re-export, optional to drop total export and pivot long to match **Trade_Update** and **Trade_Full** data frames' variables (i.e., columns) and types. Section **3. Calculate the trade balance** will need to be updated to allow for the distinction between domestic, re-export or total-export. Additional work on the **BC_AF_Trade_Tool_Build.Rmd** will also need to be undertaken.

# 1. Set-up & Library

As of January 2026, SITS cannot yet directly connect to a SharePoint URL to access the shared Unpublished Data library. The interim workaround is to sync that library to the user's Desktop and change the URL manually. Remember to replace "\\" with "/" and note that the timeout settings is 10 mins because the zip file is large and the default timeout of 1 min is insufficient to download and unzip the file
>>>>>>> Stashed changes

```{r Set-up, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# Set working directory

knitr::opts_knit$set(root.dir = "C:/Users/lebautis/Government of BC/SICI Data Library Subsite - Unpublished Data")
```

```{r Library}

# Load library
library(pacman)
p_load(dplyr,
       data.table,
       tidyr,
       lubridate,
       tictoc,
       splitstackshape,
       stringr)
```

# Load and read latest data

Export data

<<<<<<< Updated upstream
```{r Export Latest}
=======
-   a\. Domestic export

-   b\. Import

See the top of this .Rmd for more information on total and re-export integration.

## 2a. Domestic Export

This chunk of code works off the user's desktop and the directory will need to be updated with their IDIR:

```         
"C:/Users/[replace with IDIR]/Desktop/"
```

The URL for the .zip file changes and needs updating. It is formatted like:

```         
https://www150.statcan.gc.ca/n1/pub/##-###-x/#######/zip/CIMT-CICM_Dom_Exp_YYYY.zip
```

Confirm that file_inside_zip is the correct one to pull from the zip_contents then update the references for [**out_dir**]{.underline} and [**file.path**]{.underline} with the latest year:

```         
C:/Users/[replace with IDIR]/Desktop/CIMT_CICM_YYYY/CIMT-CICM_Dom_Exp_YYYY
```

Until BC Gov admins grant access, SharePoint files cannot easily be pulled using the **M365** R package. The temporary workaround is to sync the Unpublished Data Library with each user's desktop which needs to be updated in the code:

```         
"C:/Users/[replace with IDIR]/Government of BC/SICI Data Library Subsite - Unpublished Data"
```

When all of the above references have been updated, following chunk will:

-   Download the zip file: load the specific file with export value data at the HS8-level into a full data frame called **DomExport_Update**.

-   Clean the data: rename columns and specifying types (e.g., text, numeric, etc.)

-   Filter the full data frame: load the specific list of HS8 codes from AAFC's CATSNET related to agriculture and food into a data framed called **Commodity_REF** and left join with the full data frame, **DomExport_Update,** to filter only for matching HS8 codes

-   Remember to replace "\\" with "/"

```{r Domestic Export Update}

# starts the timer (optional)
>>>>>>> Stashed changes
tic()

# Set the working directory to desktop
setwd("C:/Users/lebautis/Desktop/")

# Step 1: Create a temporary file
temp_file <- tempfile()

# Step 2: Fetch the online file using download.file()
# Replace 'url_of_the_file' with the actual URL of the file you want to download
url <- "https://www150.statcan.gc.ca/n1/pub/71-607-x/2021004/zip/CIMT-CICM_Dom_Exp_2024.zip"
download.file(url, temp_file)

# Step 3: Extract the file from the temp file using unz() command
# Replace 'file_inside_zip' with the actual name of the file inside the ZIP archive
file_inside_zip <- "CIMT-CICM_Dom_Exp_2024/ODPFN016_202405N.csv"
Export <- read.csv(unz(temp_file, file_inside_zip))

<<<<<<< Updated upstream
# Step 4: Remove the temp file using unlink()
=======
# Create a temporary file to store the ZIP
zip_file <- tempfile(fileext = ".zip")

# Download the ZIP
download.file(
  url      = url,
  destfile = zip_file,
  mode     = "wb"   # important for Windows
)

# List the contents of the ZIP file
zip_contents <- unzip(zip_file, list = TRUE)

# Select the file in the 4th row, 1st column
file_inside_zip <- zip_contents[12, 1]

# Check what file was selected
file_inside_zip

# Extract specific file 
out_dir <- "C:/Users/lebautis/Desktop/CIMT_CICM_2025"

unzip(
  zip_file,
  files = file_inside_zip,
  exdir = out_dir
)

# Full path to the extracted CSV file
csv_file <- file.path("C:/Users/lebautis/Desktop/CIMT_CICM_2025/CIMT-CICM_Dom_Exp_2025", basename(file_inside_zip))

# Read the CSV with specified column classes
DomExport_Update <- read.csv(
  csv_file,
  colClasses = c(
    HS8      = "character",
    Value.Valeur    = "numeric",
    Quantity.Quantité = "numeric"
  ),
  stringsAsFactors = FALSE
)

# Remove the temp file using unlink()
>>>>>>> Stashed changes
unlink(temp_file)

# Set the working directory to SharePoint
setwd("C:/Users/lebautis/Government of BC/SICI Data Library Subsite - Unpublished Data")

# Load the list of agriculture, seafood and food manufacturing HS codes 
Commodity_REF <- fread("Commodity_Classification.csv",
                       colClasses = c(HS8_Code = "character"))

# Read the CSV file into a data frame
Export_Update <- read.csv(file = "ODPFN016_202412N.csv", stringsAsFactors = FALSE, colClasses = c(HS8 = "character", Value = "numeric", Quantity = "numeric"))

<<<<<<< Updated upstream
<<<<<<< Updated upstream
=======
# Rename variables then join left with the Commodity_REF to filter for relevant HS codes only and merge with Commodity_REF to filter for agrifood HS8 codes
>>>>>>> Stashed changes
=======
# Rename variables then join left with the Commodity_REF to filter for relevant HS codes only and merge with Commodity_REF to filter for agrifood HS8 codes
>>>>>>> Stashed changes

# Rename variables then join left with the Commodity_REF to fileter for relevant HS codes only
Export2024 <- Export_Update %>% 
  rename (Date = `YearMonth.AnnéeMois`,
          HS8_code = `HS8`,
          Country = `Country.Pays`,
          State = `State.État`,
          Value = `Value.Valeur`,
          Quantity = `Quantity.Quantité`,
          UOM = `Unit.of.Measure.Unité.de.Mesure`
  ) %>%
  merge(Commodity_REF,by="HS8_code") %>% 
  select(1:8)

# reformat the date column
Export_Update$Date <- ym(Export_Update$Date)


# to write code: bind with Trade FULL


toc()
```

Import data

```{r Import Latest}

tic()


# Set the working directory to desktop
setwd("C:/Users/lebautis/Desktop/")

# Step 1: Create a temporary file
temp_file <- tempfile()

# Step 2: Fetch the online file using download.file()
# Replace 'url_of_the_file' with the actual URL of the file you want to download
url <- "https://www150.statcan.gc.ca/n1/pub/71-607-x/2021004/zip/CIMT-CICM_Dom_Exp_2024.zip"
download.file(url, temp_file)

# Step 3: Extract the file from the temp file using unz() command
# Replace 'file_inside_zip' with the actual name of the file inside the ZIP archive
file_inside_zip <- "CIMT-CICM_Dom_Exp_2024/ODPFN016_202405N.csv"
Import <- read.csv(unz(temp_file, file_inside_zip))

<<<<<<< Updated upstream
# Step 4: Remove the temp file using unlink()
unlink(temp_file)

# Read the CSV file into a data frame
Import_Update <- read.csv("ODPFN014_202412N.csv", stringsAsFactors = FALSE, colClasses = c(HS10 = "character", Value = "numeric", Quantity = "numeric"))

# Set the working directory to SharePoint
setwd("C:/Users/lebautis/Government of BC/SICI Data Library Subsite - Unpublished Data")


# Load the list of agriculture, seafood and food manufacturing HS codes 
Commodity_REF <- read.csv("HS8X_2022_AAFC_REF.csv", colClasses = "character")
Commodity_REF <- Commodity_REF %>% rename (HS8_code = HS8_Code)
=======
# Create a temporary file to store the ZIP
zip_file <- tempfile(fileext = ".zip")

# Download the ZIP
download.file(
  url      = url,
  destfile = zip_file,
  mode     = "wb"   # important for Windows
)

# List the contents of the ZIP file
zip_contents <- unzip(zip_file, list = TRUE)

# Select the file in the 4th row, 1st column
file_inside_zip <- zip_contents[11, 1]

# Check what file was selected
file_inside_zip

# Extract specific file 
out_dir <- "C:/Users/lebautis/Desktop/CIMT_CICM_2025"

unzip(
  zip_file,
  files = file_inside_zip,
  exdir = out_dir
)

# Full path to the extracted CSV file
csv_file <- file.path("C:/Users/lebautis/Desktop/CIMT_CICM_2025/CIMT-CICM_Imp_2025", basename(file_inside_zip))

# Read the CSV with specified column classes
Import_Update <- read.csv(
  csv_file,
  colClasses = c(
    HS10      = "character",
    Value.Valeur    = "numeric",
    Quantity.Quantité = "numeric"
  ),
  stringsAsFactors = FALSE
)

# Remove the temp file using unlink()
unlink(temp_file)

<<<<<<< Updated upstream
>>>>>>> Stashed changes
=======
>>>>>>> Stashed changes
# Rename variables
Import_Update <- Import_Update %>% 
  rename (Date = `YearMonth.AnnéeMois`,
          HS10_code = `HS10`,
          Country = `Country.Pays`,
          State = `State.État`,
          Value = `Value.Valeur`,
          Quantity = `Quantity.Quantité`,
          UOM = `Unit.of.Measure.Unité.de.Mesure`
  ) %>%
  select(1:8)

# reformat the date column
Import_Update$Date <- ym(Import_Update$Date)

# Replace blank, NA, or NULL values in 'State' with 'Country'
Import_Update$State[is.na(Import_Update$State) | Import_Update$State == ""] <- "Country"

<<<<<<< Updated upstream
<<<<<<< Updated upstream
# Transform HS10 to HS8 by summing Value and Quantity then join left with the Commodity_REF to fileter for relevant HS codes only
=======
=======
>>>>>>> Stashed changes
# Trim first 8 characters 
>>>>>>> Stashed changes
Import_Update <- Import_Update %>%
  mutate(HS8_code = substr(HS10_code, 1, 8))  # Trim first 8 characters 
  
## create new column
Import_Update <- Import_Update %>%
  select(-HS10_code) %>%  # Remove original HS10 column
  group_by(Date, HS8_code, Country, State, Province, UOM) %>%
  summarise(
    Value = sum(Value, na.rm = TRUE),
    Quantity = sum(Quantity, na.rm = TRUE),
    .groups = "drop")

<<<<<<< Updated upstream
<<<<<<< Updated upstream
# to write code: bind with Trade FULL
Import_Update <- Import_Update %>% merge(Commodity_REF,by="HS8_code")
=======
=======
>>>>>>> Stashed changes
# Load the list of agriculture, seafood and food manufacturing HS codes 
Commodity_REF <- fread("Commodity_Classification.csv",
                       colClasses = c(HS8_Code = "character"))

# Rename variables then join left with the Commodity_REF to filter for relevant HS codes only and merge with Commodity_REF to filter for agrifood HS8 codes

DomExport_Update <- DomExport_Update %>% 
  merge(Commodity_REF,by="HS8_code") %>% 
  select(1:8)

<<<<<<< Updated upstream
>>>>>>> Stashed changes
=======
>>>>>>> Stashed changes

toc()

```

# Calculate the trade balance

```{r Calculate Trade Balance Update}
tic()

Trade_Update <- full_join(Export_Update, Import_Update,
                       by = c("HS8_code",
                              "Date",
                              "Country",
                              "Province",
                              "State",
                              "UOM"),
                       copy = FALSE,
                       suffix = c("_X", "_M"),
                       keep = NULL)



#replace NAs with 0

Trade_Update[is.na(Trade_Update)] <- 0

# calculate trade balance

Trade_Update$Value_Balance <- Trade_Update$Value_X-Trade_Update$Value_M

Trade_Update$Quantity_Balance <- Trade_Update$Quantity_X-Trade_Update$Quantity_M

# Re-arrange the columns in a useful order
Trade_Update <- Trade_Update[,c(1:5,8,6:7,9:12)]


Trade_Update <- pivot_longer(Trade_Update,
                          7:12,
                          names_to = "Estimate",
                          values_to = "Value")

toc()
```

# Append to TradeFULL

```{r APpend to TradeFULL}

# Set the working directory to the location of the CSV file
setwd("C:/Users/lebautis/Desktop/CIMTD")

# Read the CSV file into a data frame
TradeFULL <- read.csv("TradeFULL.csv", stringsAsFactors = FALSE, colClasses = c(HS8_Code = "character", Value = "numeric"))
TradeFULL <- TradeFULL %>% rename (HS8_code = HS8_Code)

TradeFULL$Date <- ymd(TradeFULL$Date)

# Ensure both data frames have the same columns
if(all(colnames(TradeFULL) == colnames(Trade_Update))) {
  # Combine the two data frames row-wise
  CombinedTradeData <- rbind(TradeFULL, Trade_Update)
  # Print the combined data
  print(CombinedTradeData)
} else {
  # If columns do not match, give an error message
  print("The columns of the two data frames do not match.")
}


```

# Write CSV

For now, upload to sharepoint manually until we figure out M365R function

```{r write CSV}

tic()

# Set the working directory to the location of the CSV file
setwd("C:/Users/lebautis/Desktop/CIMTD")

fwrite(CombinedTradeData, "TradeFULL2025.csv",
       row.names = FALSE,
       col.names = TRUE,
       buffMB = 10)

toc()
```
