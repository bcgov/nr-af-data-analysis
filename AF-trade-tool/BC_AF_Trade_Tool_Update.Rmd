---
title: "BC AF Trade Tool Update"
author: "Leila Bautista"
date: "`r Sys.Date()`"
output:
  html_document: default
  pdf_document: default
---

# Canadian International Merchandise Trade Database (CIMTD)

This RMarkdown provides chunks of R code to load, filter and combine data from Open Government [website](https://search.open.canada.ca/opendata/?sort=metadata_modified+desc&search_text=cimt&page=1). The trade data is used by the Ministry of Agriculture and Food's SITS Unit to produce various deliverables that estimate BC and other provincial trade of agriculture and food commodities.

Contact [alstats\@gov.bc.ca](mailto:alstats@gov.bc.ca) for any questions. The following are key steps:

1.  Set-up and load library
2.  Load and read the updated (i.e., latest data) for a. domestic export\* and b. import
3.  Calculate trade balance
4.  Append the update to the shared structured and time series data called [**TradeFull.csv**]{.underline}
5.  Overwrite [**TradeFull.csv**]{.underline} with the new year's data

\*A new chunk to load **c. Total export** could be written which would require binding with **a. Domestic export** to pivot wide by export type (i.e., total vs. domestic). Once pivoted wide, re-export is equal to total export less domestic export and can be calculated. After calculating re-export, optional to drop total export and pivot long to match **Trade_Update** and **Trade_Full** data frames' variables (i.e., columns) and types. Section **3. Calculate the trade balance** will need to be updated to allow for the distinction between domestic, re-export or total-export. Additional work on the **BC_AF_Trade_Tool_Build.Rmd** will also need to be undertaken.

# 1. Set-up & Library

As of January 2026, SITS cannot yet directly connect to a SharePoint URL to access the shared Unpublished Data library. The interim workaround is to sync that library to the user's Desktop and change the URL manually. Remember to replace "\\" with "/" and note that the timeout settings is 10 mins because the zip file is large and the default timeout of 1 min is insufficient to download and unzip the file

```{r Set-up, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# Set working directory

knitr::opts_knit$set(root.dir = "C:/Users/lebautis/Government of BC/SICI Data Library Subsite - Unpublished Data")

# sets the time-out option to 10 mins
options(timeout = 800)
```

```{r Library}

# Load library
library(pacman)
p_load(dplyr,
       data.table,
       tidyr,
       lubridate,
       tictoc,
       splitstackshape,
       stringr)
```

# 2. Load and read latest data

As of January 2026, there are 2 chunks of code involved to load the update for each of:

-   a\. Domestic export

-   b\. Import

See the top of this .Rmd for more information on total and re-export integration.

## 2a. Domestic Export

This chunk of code works off the user's desktop and the directory will need to be updated with their IDIR:

```         
"C:/Users/[replace with IDIR]/Desktop/"
```

The URL for the .zip file changes and needs updating. It is formatted like:

```         
https://www150.statcan.gc.ca/n1/pub/##-###-x/#######/zip/CIMT-CICM_Dom_Exp_YYYY.zip
```

Confirm that file_inside_zip is the correct one to pull from the zip_contents then update the references for [**out_dir**]{.underline} and [**file.path**]{.underline} with the latest year:

```         
C:/Users/[replace with IDIR]/Desktop/CIMT_CICM_YYYY/CIMT-CICM_Dom_Exp_YYYY
```

Until BC Gov admins grant access, SharePoint files cannot easily be pulled using the **M365** R package. The temporary workaround is to sync the Unpublished Data Library with each user's desktop which needs to be updated in the code:

```         
"C:/Users/[replace with IDIR]/Government of BC/SICI Data Library Subsite - Unpublished Data"
```

When all of the above references have been updated, view zip_contents and update the following chunk with the correct index to the file that starts with "ODPFN016\_"

-   Download the zip file: load the specific file with export value data at the HS8-level into a full data frame called **DomExport_Update**.

-   Clean the data: rename columns and specifying types (e.g., text, numeric, etc.)

-   Filter the full data frame: load the specific list of HS8 codes from AAFC's CATSNET related to agriculture and food into a data framed called **Commodity_REF** and left join with the full data frame, **DomExport_Update,** to filter only for matching HS8 codes

-   Remember to replace "\\" with "/"

```{r Dom Export Update Part 1}

# starts the timer (optional)
tic()

# Create a temporary file
temp_file <- tempfile()

# Fetch the online file using download.file()

# URL of the ZIP file
url <- "https://www150.statcan.gc.ca/n1/pub/71-607-x/2021004/zip/CIMT-CICM_Dom_Exp_2025.zip"

# Create a temporary file to store the ZIP
zip_file <- tempfile(fileext = ".zip")

# Download the ZIP

download.file(url, zip_file, mode = "wb", method = "libcurl")

# List the contents of the ZIP file
zip_contents <- unzip(zip_file, list = TRUE)

csv_file <- zip_contents$Name[
  grepl("ODPFN016_.*\\.csv$", zip_contents$Name)
]


# Read the CSV with specified column classes
  DomExport_Update <- read.csv(
     unz(zip_file, csv_file),
    colClasses = c(
      HS8      = "character",
      Value.Valeur    = "numeric",
      Quantity.Quantité = "numeric"
    ),
    stringsAsFactors = FALSE
  )
  
# Remove the temp file using unlink()
  unlink(temp_file)


# Rename variables then join left with the Commodity_REF to filter for relevant HS codes only

DomExport_Update <- DomExport_Update %>% 
  rename (Date = `YearMonth.AnnéeMois`,
          HS8_code = `HS8`,
          Country = `Country.Pays`,
          State = `State.État`,
          Value = `Value.Valeur`,
          Quantity = `Quantity.Quantité`,
          UOM = `Unit.of.Measure.Unité.de.Mesure`
  ) %>% 
  select(1:8)
  
# reformat the date column
DomExport_Update$Date <- ym(DomExport_Update$Date)

# Load the list of agriculture, seafood and food manufacturing HS codes 
Commodity_REF <- fread("C:/Users/lebautis/Government of BC/SICI Data Library Subsite - Unpublished Data/CATSNET HS8.csv",
                       colClasses = c(HS8_code = "character"))


DomExport_Update <- DomExport_Update %>% 
  merge(Commodity_REF,by="HS8_code") %>%
  rename(HS_description = HS8_description)

# end timer and report
toc()
```

## 2b. Import

This chunk of code works off the user's desktop and the directory will need to be updated with their IDIR:

```         
"C:/Users/[replace with IDIR]/Desktop/"
```

The URL for the .zip file changes and needs updating. It is formatted like:

```         
https://www150.statcan.gc.ca/n1/pub/##-##-x/#######/zip/CIMT-CICM_Imp_YYYY.zip
```

Confirm that file_inside_zip is the correct one to pull from the zip_contents then update the references for [**out_dir**]{.underline} and [**file.path**]{.underline} with the latest year:

```         
C:/Users/[replace with IDIR]/Desktop/CIMT_CICM_YYYY/CIMT-CICM_Imp_YYYY
```

Until BC Gov admins grant access, SharePoint files cannot easily be pulled using the **M365** R package. The temporary workaround is to sync the Unpublished Data Library with each user's desktop which needs to be updated in the code:

```         
"C:/Users/[replace with IDIR]/Government of BC/SICI Data Library Subsite - Unpublished Data"
```

Remember that import data is not available at the level 8 but rather 10 level. When all of the above references have been updated, view zip_contents and update the following chunk with the correct index to the file that starts with "ODPFN014"

-   Download the zip file: load the specific file with export value data at the HS10-level into a full data frame called **Import_Update**

-   Clean the data: rename columns and specifying types (e.g., text, numeric, etc.)

-   Filter the full data frame: load the specific list of HS10 codes from AAFC's CATSNET related to agriculture and food into a data framed called **Commodity_REF** and left join with the full data frame, **Import_Update,** to filter only for matching HS10 codes

-   Aggregate the value of imports at HS10 level up to HS8 level then drop HS10 variable. As of January 2026, the code also includes quantity data but the results are not reliable due to potentially differences in unit of measure (e.g., kilograms vs. heads)

-   Remember to replace "\\" with "/"

```{r Import Update Part 1}

# starts the timer (optional)
tic()

# Create a temporary file
temp_file <- tempfile()

# Fetch the online file using download.file()

# URL of the ZIP file
url <- "https://www150.statcan.gc.ca/n1/pub/71-607-x/2021004/zip/CIMT-CICM_Imp_2025.zip"

# Create a temporary file to store the ZIP
zip_file <- tempfile(fileext = ".zip")

# Download the ZIP

download.file(url, zip_file, mode = "wb", method = "libcurl")

# List the contents of the ZIP file
zip_contents <- unzip(zip_file, list = TRUE)

csv_file <- zip_contents$Name[
  grepl("ODPFN014_.*\\.csv$", zip_contents$Name)
]


# Read the CSV with specified column classes
  Import_Update <- read.csv(
     unz(zip_file, csv_file),
    colClasses = c(
      HS10      = "character",
      Value.Valeur    = "numeric",
      Quantity.Quantité = "numeric"
    ),
    stringsAsFactors = FALSE
  )
  
  # Remove the temp file using unlink()
  unlink(temp_file)
  
  
  # Rename variables
  Import_Update <- Import_Update %>% 
    rename (Date = `YearMonth.AnnéeMois`,
            HS10_code = `HS10`,
            Country = `Country.Pays`,
            State = `State.État`,
            Value = `Value.Valeur`,
            Quantity = `Quantity.Quantité`,
            UOM = `Unit.of.Measure.Unité.de.Mesure`
    ) %>%
    select(1:8)
  
  # reformat the date column
Import_Update$Date <- ym(Import_Update$Date)

# Replace blank, NA, or NULL values in 'State' with 'Country'
Import_Update$State[is.na(Import_Update$State) | Import_Update$State == ""] <- "Country"

# Load the list of agriculture, seafood and food manufacturing HS codes 
Commodity_REF <- fread("C:/Users/lebautis/Government of BC/SICI Data Library Subsite - Unpublished Data/CATSNET HS10.csv",
                       colClasses = c(HS10_code = "character"))


# Join left with the Commodity_REF to filter for relevant HS codes only
Import_Update <- Import_Update %>% 
  merge(Commodity_REF,by="HS10_code") %>%
  rename(HS_description = HS10_description) %>%
  select(-HS10_code)

# end timer and report
toc()

```

# 3. Calculate the trade balance

To calculate the trade balance, ensure that the updated export and import trade data are loaded in the environment. The chunk also adds an identifying column by adding the suffixes "X" for domestic export and "\_M" for imports. The final step in this chunk is to re-arrange columns and to pivot the data longer to match the structure of **TradeFull.csv**.

```{r Calculate Trade Balance Update}

# Full join Export_Update with Import_Update into Trade_Update
Trade_Update <- full_join(DomExport_Update, Import_Update,
                       by = c("HS_description",
                              "Date",
                              "Country",
                              "Province",
                              "State",
                              "UOM"),
                       copy = FALSE,
                       suffix = c("_X", "_M"),
                       keep = NULL)

#replace NAs with 0
Trade_Update[is.na(Trade_Update)] <- 0

# calculate trade balance for for trave value
Trade_Update$Value_Balance <- Trade_Update$Value_X-Trade_Update$Value_M

# Calculate trade balance for trade quantity
Trade_Update$Quantity_Balance <- Trade_Update$Quantity_X-Trade_Update$Quantity_M

# Re-arrange the columns in a useful order
Trade_Update <- Trade_Update[,c(1,9,2:5,8,6:7,10:13)]

# Pivot to the format for easy binding with TradeFull.csv
Trade_Update <- pivot_longer(Trade_Update,
                          8:13,
                          names_to = "Estimate",
                          values_to = "Value")

# Treat HS8 as characters and drop the HS description

Trade_Update <- Trade_Update %>%
  mutate(HS8_code = as.character(HS8_code)) %>%
  select(-HS_description) %>%
  filter(!grepl("^Quantity_", as.character(Estimate)))

```

# 4. Append update to full time series

As of January 2026, files in the SharePoint cannot be accessed using the **M365** package until BC Gov administrators grant the unit members access. The workaround is to sync the **Unpublished Data Library** in each user's device and read files accordingly. That means this chunk of code works off the user's desktop and the directory will need to be updated with their IDIR:

```         
"C:/Users/[replace with IDIR]/Government of BC/SICI Data Library Subsite - Unpublished Data"
```

After the above directory URL has been updated, the rest of the chunk will load the shared **TradeFull.csv** time series data set into the environment. Remember to replace "\\" with "/" and note that the timeout settings is 10 mins because the zip file is large and the default timeout of 1 min is insufficient to download and the **TradeFull.csv** file.

```{r Append to TradeFULL}

# starts the timer (optional)
tic()

# Set the working directory 
setwd("C:/Users/lebautis/Government of BC/SICI Data Library Subsite - Unpublished Data")

# Read the CSV file into a data frame
TradeFULL <- read.csv("TradeFULL.csv", stringsAsFactors = FALSE, colClasses = c(HS8_code = "character", Value = "numeric"))

# Specify date as type
TradeFULL$Date <- ymd(TradeFULL$Date)

### ONLY RUN TO CLEAN 2024 ONWARDS
TradeFULL <- TradeFULL %>%
  mutate(Date = as.Date(Date)) %>%
  filter(Date < as.Date("2024-01-01"))



# Combine the two data frames row-wise
CombinedTradeData <- rbindlist(
  list(TradeFULL, Trade_Update),
  use.names = TRUE,
  fill = TRUE
)

# end timer and report
toc()
```

# 5. Write CSV

As of January 2026, files in the SharePoint cannot be accessed using the **M365** package until BC Gov administrators grant the unit members access. The workaround is to sync the **Unpublished Data Library** in each user's device and read files accordingly. That means this chunk of code works off the user's desktop and the directory will need to be updated with your IDIR:

```         
"C:/Users/[replace with IDIR]/Government of BC/SICI Data Library Subsite - Unpublished Data"
```

After the above directory URL has been updated, the rest of the chunk uses the fwrite function (fastest) to overwrite the synced copy on the user's device. It can take a moment for the file to save and even more for the synced copy to upload to the cloud version of the Unpublished Data Library SharePoint site.

```{r write CSV}

# starts the timer (optional)
tic()

# Set the working directory to the location of the CSV file
setwd("C:/Users/lebautis/Government of BC/SICI Data Library Subsite - Unpublished Data")

fwrite(CombinedTradeData, "TradeFULL.csv",
       row.names = FALSE,
       col.names = TRUE,
       buffMB = 10)

# end timer and report
toc()
```
